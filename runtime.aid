runtime {
  path=src/runtime;

  Executes the compiled plan by running all leaf nodes in parallel.
  
  For each leaf, the runtime:
    1. Reads the .leaf.json file
    2. Creates the outputPath directory if needed
    3. Runs any whitelisted commands in that directory
    4. Generates files listed in files array, writing them to outputPath
    5. Prepends a generated file header to each file (see below)
  
  Generated file headers:
    When writing a file, the runtime deterministically prepends a comment header.
    The header says the file is generated and points to the relevant .aid file to edit.
    The comment style depends on file extension:
    
    ```
    .ts, .js, .tsx, .jsx: // Generated by aidef. Edit <source.aid> to change behavior.
    .py, .yaml, .yml:     # Generated by aidef. Edit <source.aid> to change behavior.
    .css, .scss:          /* Generated by aidef. Edit <source.aid> to change behavior. */
    .html, .xml, .svg, .md: <!-- Generated by aidef. Edit <source.aid> to change behavior. -->
    .json: (no header, JSON doesn't support comments)
    ```
    
    The source.aid path comes from the leaf's sourceAid field.
  
  Exports a run function that takes outputDir and apiKey.
  Finds all leaf.json files, executes them in parallel with progress reporting.

  leafExecutor {
    Executes a single leaf node using @google/genai (Google Gemini).
    
    Exports:
      - GenLeaf interface: { path, dir, outputPath, sourceAid, prompt, files, commands }
      - executeLeaf(leaf: GenLeaf, apiKey: string, outputDir: string, logger: Logger): Promise<void>
    
    Implementation:
      1. First run any commands from leaf.commands (must be whitelisted)
      2. Use GoogleGenAI chat with write_file tool to generate each file
      3. write_file tool: { path: string, content: string } - writes to outputPath/path
      4. Continue chat until all files in leaf.files are written
      5. Log each file write to logger
    
    The prompt sent to LLM includes:
      - leaf.prompt (the code generation instructions)
      - List of files to create
      - "Use the write_file tool to create each file"
  }

  commandWhitelist {
    Leaf nodes can request shell commands, but only whitelisted ones run.
    Users can configure additional allowed commands in .aidrc or project config.
    The analyse mode suggests new commands to whitelist based on what leaves tried to run.
    
    Exports DEFAULT_WHITELIST array and isAllowed function.
    Default allows: bun init, bun install, bun add.
  }

  logger {
    Stores all AI calls and command executions in runtime.log.jsonl.
    Each line is a JSON object with timestamp, type, leaf path, and details.
    Used by analyse mode to review what happened.
    
    Exports LogEntry interface and createLogger function.
  }
}
