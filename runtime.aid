runtime {
  path=src/runtime;

  Executes the compiled plan by running all leaf nodes in parallel.
  
  For each leaf, the runtime:
    1. Reads the .leaf.json file
    2. Creates the outputPath directory if needed
    3. Runs any whitelisted commands in that directory
    4. Generates files listed in files array, writing them to outputPath
    5. Prepends a generated file header to each file
  
  Generated file headers:
    The runtime deterministically prepends a comment header pointing to the source .aid file.
    Comment style depends on file extension (// for JS/TS, # for Python/YAML, etc.).
    JSON files get no header since JSON doesn't support comments.
    The source.aid path comes from the leaf's sourceAid field.
  
  Exports a run function that takes outputDir and apiKey.
  Finds all leaf.json files, executes them in parallel with progress reporting.

  leafExecutor {
    Executes a single leaf node using Google Gemini via @google/genai package (GoogleGenAI class, NOT @google/generative-ai or GoogleGenerativeAI).
    
    Exports executeLeaf function and GenLeaf interface.
    
    Uses a chat-based approach with a write_file tool to generate each file.
    Continues the chat until all files in the leaf are written.
    Logs each file write to the logger.
    
    CRITICAL: The code generation LLM must NEVER DIVERGE from the leaf prompt instructions.
    Follow them to the letter. When the prompt specifies exact package names, class names,
    function signatures, or API patterns, use them EXACTLY as written.
    Do NOT substitute similar-sounding alternatives:
      - Use @google/genai, NOT @google/generative-ai
      - Use GoogleGenAI class, NOT GoogleGenerativeAI
      - Use genai.chats.create(), NOT model.startChat()
    If the prompt says "GoogleGenAI", the generated code MUST use "GoogleGenAI".
  }

  commandWhitelist {
    Leaf nodes can request shell commands, but only whitelisted ones run.
    Users can configure additional allowed commands in .aidrc or project config.
    The analyse mode suggests new commands to whitelist based on what leaves tried to run.
    
    Exports DEFAULT_WHITELIST array and isAllowed function.
    Default allows: bun init, bun install, bun add.
  }

  logger {
    Stores all AI calls and command executions in runtime.log.jsonl.
    Each line is a JSON object with timestamp, type, leaf path, and details.
    Used by analyse mode to review what happened.
    
    Exports LogEntry interface and createLogger function.
  }
}
