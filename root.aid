/*
  AIDef - A programming language where AI is the runtime
  
  This is AIDef's own root.aid, defining itself.
  
  Compiles .aid files into a tree of .aidg files,
  then builds code from leaf nodes. No database -
  files are the source of truth.
*/

A CLI tool that compiles .aid files into code;

// === Hard requirements ===
TypeScript strict mode;
Bun runtime, not Node;
No database - files are the source of truth;
Each submodule must be independently runnable;

// === File types ===
aid-files {
  // User source files, nginx-like natural language
  parse with module blocks: name { };
  parse query filters: "question?" { };
  resolve imports recursively;
  preserve code blocks as literal prose;
  strip comments before AI sees content;
}

aidg-files {
  // Generated nodes, same nginx-like format
  fully resolved (no imports);
  users can inspect and copy snippets back;
}

aidc-files {
  // Context for nodes, YAML format
  contains all potentially relevant info from ancestors;
  context filter agent selects relevant subset;
}

aidq-files {
  // Questions/uncertainties, YAML format
  users answer via --browse or direct edit;
}

// === Core architecture ===

parser {
  parse .aid file syntax;
  
  lexer {
    leaf=true;
    tokenize: identifiers, braces, strings, numbers, semicolons;
    handle comments and code blocks;
    track line/column for error messages;
  }
  
  ast {
    leaf=true;
    build tree from tokens;
    represent: modules, query filters, parameters, prose;
  }
  
  resolver {
    leaf=true;
    resolve import statements;
    detect circular imports;
    inline non-.aid files as prose;
  }
}

compiler {
  // Phase 1: generate .aidg tree from root.aid
  
  reads .aid files, outputs .aid-gen/ folder;
  each node produces node.aidc with full context;
  
  compile-node {
    leaf=true;
    serialize AST to spec string;
    call provider to compile;
    write .aidg, .aidc, .aidq files;
  }
  
  context-builder {
    leaf=true;
    gather all potentially relevant context;
    output as node.aidc (YAML);
    contains: interfaces, constraints, suggestions, utilities;
    annotate where each directive originated;
  }
  
  differ {
    leaf=true;
    compare new vs existing .aidg outputs;
    skip subtrees with identical interfaces;
    use interface hashes for fast comparison;
  }
  
  writer {
    leaf=true;
    write .aidg, .aidc, .aidq files;
    create directory structure in .aid-gen/;
  }
}

generator {
  // Phase 2: execute leaf nodes to produce code
  
  context-filter {
    leaf=true;
    read node.aidc;
    determine relevant subset for this generation;
    apply token budget limits;
  }
  
  executor {
    leaf=true;
    invoke AI with filtered context + node.aidg;
    output code to build/ folder;
    add source comment headers;
  }
  
  checks {
    leaf=true;
    // TODO: post-generation enforcement
    // verify outputs match declared interfaces
    // flag deviations for review
  }
}

cli {
  use Bun.argv for argument parsing;
  
  run {
    leaf=true;
    default mode: compile .aid tree;
    stream .aidq items as they appear;
    parallel compilation of siblings;
  }
  
  browse {
    leaf=true;
    TUI mode with --browse flag;
    watch compilation progress;
    browse .aidg tree structure;
    view and answer .aidq questions inline;
    abort early if needed;
  }
  
  build {
    leaf=true;
    --build flag: execute leaf nodes;
    generate code to ./build/;
    only after user approval;
  }
  
  estimate {
    leaf=true;
    --estimate flag: show cost estimate;
    count nodes, estimate tokens;
    abort if exceeds --max-cost threshold;
  }
  
  auth {
    leaf=true;
    --auth flag: TUI for LLM provider configuration;
    support multiple providers: OpenAI, Anthropic, etc;
    store credentials via environment variables;
    test connection before saving;
  }
}

providers {
  // LLM provider abstraction via Vercel AI SDK
  
  common interface for all providers;
  
  anthropic {
    leaf=true;
    @ai-sdk/anthropic adapter;
    Claude models;
  }
  
  openai {
    leaf=true;
    @ai-sdk/openai adapter;
    GPT models;
  }
  
  call-logger {
    leaf=true;
    log all AI calls to calls.jsonl;
    track tokens, duration, success/failure;
  }
}

questions {
  leaf=true;
  generate .aidq files (YAML) for uncertainties;
  parse answered questions;
  inject answers into next compilation run;
}

// === Query filters (apply to matching modules) ===

"is this a leaf module?" {
  add unit tests;
  use bun test;
}

"needs file I/O?" {
  prefer Bun.file over fs;
}

"needs HTTP?" {
  use Bun.serve;
}

"needs shell commands?" {
  use Bun.$;
}

"is this a TUI component?" {
  consider ink or blessed;
  keep it simple - progress and tree view;
}
